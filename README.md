# CPU Auto Remediation System using Docker, Prometheus, and LLM (Ollama)

This project automatically detects CPU spikes inside a Docker container, analyzes system logs using a local LLM (via Ollama), performs root cause analysis (RCA), and triggers remediation actions including container restart and email notifications via AWS SNS.

---

## ğŸ“Œ Features

- Monitors CPU usage in real-time (via Prometheus)
- Detects CPU spikes in Docker containers
- Automatically restarts containers during CPU spikes
- Collects system logs and sends to LLM (Ollama) for RCA
- Sends RCA summaries to email using Amazon SNS
- Works entirely on local setup (LLM and monitoring stack)

---

## ğŸ§ª How It Works

1. `cpu_monitor.py` monitors container CPU via Prometheus API.
2. On spike detection, it triggers `remediation.py`.
3. `remediation.py`:
   - Restarts the container
   - Calls `log_analysis.py` to collect logs and analyze with LLM
   - Send RCA & notification via email using AWS SNS

---

## ğŸ› ï¸ Prerequisites

- Ubuntu EC2 Instance
- Docker installed
- Prometheus running locally (port 9090)
- Python 3.10+
- Ollama installed (`ollama serve`)
- AWS SNS setup with topic and permissions
- GitHub repo for version control

---

## ğŸ§° Installation

```bash
# Clone the repo
git clone https://github.com/your-username/cpu-auto-remediation.git
cd cpu-auto-remediation

# Install dependencies
pip install -r requirements.txt
ğŸ”„ Run the System

# Start Prometheus (if not already running)
./prometheus --config.file=prometheus.yml &

# Start Ollama
ollama serve &

# Start CPU monitoring
python3 cpu_monitor.py
ğŸš¨ Simulate a CPU Spike
Inside your Docker container, run:

bash
Copy
Edit
python3 /scripts/spike_simulator.py
This creates a heavy loop using CPU to test the auto-remediation workflow.

ğŸ“§ AWS SNS Configuration
Make sure your EC2 instance has IAM role or AWS credentials set (~/.aws/credentials) to publish messages to the SNS topic.

ğŸ“¬ Output
Auto container restart

RCA generated by LLM

Email sent with CPU spike details and remediation outcome

âœ… Tested On
Ubuntu 22.04 (EC2)

Docker 24.x

Prometheus 2.x

Python 3.10

Ollama (with mistral or similar LLM)

ğŸ™Œ Author
Dhyanesh
