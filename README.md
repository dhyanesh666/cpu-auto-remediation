# CPU Auto Remediation System using Docker, Prometheus, and LLM (Ollama)

This project automatically detects CPU spikes inside a Docker container, analyzes system logs using a local LLM (via Ollama), performs root cause analysis (RCA), and triggers remediation actions including container restart and email notifications via AWS SNS.

---

## 📌 Features

- Monitors CPU usage in real-time (via Prometheus)
- Detects CPU spikes in Docker containers
- Automatically restarts containers during CPU spikes
- Collects system logs and sends to LLM (Ollama) for RCA
- Sends RCA summaries to email using Amazon SNS
- Works entirely on local setup (LLM and monitoring stack)

---

## 🧪 How It Works

1. `cpu_monitor.py` monitors container CPU via Prometheus API.
2. On spike detection, it triggers `remediation.py`.
3. `remediation.py`:
   - Restarts the container
   - Calls `log_analysis.py` to collect logs and analyze with LLM
   - Send RCA & notification via email using AWS SNS

---

## 🛠️ Prerequisites

- Ubuntu EC2 Instance
- Docker installed
- Prometheus running locally (port 9090)
- Python 3.10+
- Ollama installed (`ollama serve`)
- AWS SNS setup with topic and permissions
- GitHub repo for version control

---

## 🧰 Installation

```bash
# Clone the repo
git clone https://github.com/your-username/cpu-auto-remediation.git
cd cpu-auto-remediation

# Install dependencies
pip install -r requirements.txt
🔄 Run the System

# Start Prometheus (if not already running)
./prometheus --config.file=prometheus.yml &

# Start Ollama
ollama serve &

# Start CPU monitoring
python3 cpu_monitor.py
🚨 Simulate a CPU Spike
Inside your Docker container, run:

bash
Copy
Edit
python3 /scripts/spike_simulator.py
This creates a heavy loop using CPU to test the auto-remediation workflow.

📧 AWS SNS Configuration
Make sure your EC2 instance has IAM role or AWS credentials set (~/.aws/credentials) to publish messages to the SNS topic.

📬 Output
Auto container restart

RCA generated by LLM

Email sent with CPU spike details and remediation outcome

✅ Tested On
Ubuntu 22.04 (EC2)

Docker 24.x

Prometheus 2.x

Python 3.10

Ollama (with mistral or similar LLM)

🙌 Author
Dhyanesh
